#!/usr/bin/env python3
"""
K-Startup ì‚¬ì—…ê³µê³  ëª¨ë‹ˆí„°ë§ ì—ì´ì „íŠ¸
- ë§¤ì¼ ì˜¤ì „ 9ì‹œ(KST) GitHub Actionsì— ì˜í•´ ìë™ ì‹¤í–‰
- K-Startup ì§„í–‰ ì¤‘ ì‚¬ì—…ê³µê³  ëª©ë¡ ìˆ˜ì§‘
- ìƒˆ ê³µê³  ë°œê²¬ ì‹œ: PDF ë‹¤ìš´ë¡œë“œ â†’ ìê²©ìš”ê±´ ë¶„ì„ â†’ í”„ë¡œí•„ ëŒ€ì¡°
- ì§€ì› ê°€ëŠ¥í•œ ê³µê³ ëŠ” ì‹ ì²­ ì„œë¥˜ ì´ˆì•ˆê¹Œì§€ ì‘ì„±
- ê²°ê³¼ë¥¼ Supabase ì €ì¥ + í…”ë ˆê·¸ë¨ ë°œì†¡

Supabase í•„ìš” í…Œì´ë¸”:
  - user_profile      : ê¸°ì—…/ê°œì¸ í”„ë¡œí•„ (id=1 ê³ ì •)
  - kstartup_announcements : ì²˜ë¦¬ëœ ê³µê³  ê¸°ë¡
"""

import os
import re
import sys
import json
import time
import urllib.request
import urllib.parse
import urllib.error
from datetime import datetime, timezone, timedelta
from io import BytesIO

import requests
from bs4 import BeautifulSoup
import pypdf
import anthropic

KST = timezone(timedelta(hours=9))

KSTARTUP_BASE = "https://www.k-startup.go.kr"
KSTARTUP_LIST_URL = f"{KSTARTUP_BASE}/web/contents/bizpbanc-ongoing.do"
KSTARTUP_API_URL = f"{KSTARTUP_BASE}/web/contents/bizpbanc-ongoing-ajax.do"

SESSION_HEADERS = {
    "User-Agent": (
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/120.0.0.0 Safari/537.36"
    ),
    "Accept-Language": "ko-KR,ko;q=0.9,en;q=0.8",
    "Referer": KSTARTUP_LIST_URL,
}


# ---------------------------------------------------------------------------
# Supabase ê³µí†µ
# ---------------------------------------------------------------------------

def _supabase_headers() -> dict:
    key = os.environ.get("SUPABASE_SERVICE_ROLE_KEY", "")
    return {
        "apikey": key,
        "Authorization": f"Bearer {key}",
        "Content-Type": "application/json",
    }


def _supabase_get(path: str) -> list:
    url = os.environ.get("SUPABASE_URL", "").rstrip("/")
    key = os.environ.get("SUPABASE_SERVICE_ROLE_KEY", "")
    if not url or not key:
        return []
    req = urllib.request.Request(f"{url}{path}", headers=_supabase_headers())
    try:
        with urllib.request.urlopen(req, timeout=15) as resp:
            return json.loads(resp.read().decode())
    except Exception as e:
        print(f"Supabase GET ì‹¤íŒ¨ ({path}): {e}", file=sys.stderr)
        return []


def _supabase_post(path: str, data: dict) -> bool:
    url = os.environ.get("SUPABASE_URL", "").rstrip("/")
    if not url:
        return False
    payload = json.dumps(data, ensure_ascii=False).encode("utf-8")
    req = urllib.request.Request(
        f"{url}{path}",
        data=payload,
        headers={**_supabase_headers(), "Prefer": "return=minimal"},
        method="POST",
    )
    try:
        with urllib.request.urlopen(req, timeout=15) as resp:
            return resp.status in (200, 201)
    except urllib.error.HTTPError as e:
        print(f"Supabase POST ì‹¤íŒ¨ ({e.code}): {e.read().decode()}", file=sys.stderr)
        return False


# ---------------------------------------------------------------------------
# 1. ì‚¬ìš©ì í”„ë¡œí•„ ë¡œë“œ
# ---------------------------------------------------------------------------

def load_user_profile() -> dict:
    """Supabase user_profile í…Œì´ë¸”(id=1)ì—ì„œ ì‚¬ìš©ì í”„ë¡œí•„ ë¡œë“œ."""
    rows = _supabase_get("/rest/v1/user_profile?id=eq.1")
    if rows:
        print(f"  í”„ë¡œí•„ ë¡œë“œ: {rows[0].get('company_name', '(ì´ë¦„ ì—†ìŒ)')}")
        return rows[0]
    print("  ê²½ê³ : user_profile í…Œì´ë¸”ì— ë°ì´í„° ì—†ìŒ. Supabaseì—ì„œ ì„¤ì • í•„ìš”.", file=sys.stderr)
    return {}


# ---------------------------------------------------------------------------
# 2. ì²˜ë¦¬ëœ ê³µê³  ID ë¡œë“œ
# ---------------------------------------------------------------------------

def get_seen_ids() -> set:
    """ì´ë¯¸ ì²˜ë¦¬í•œ ê³µê³  ID ëª©ë¡."""
    rows = _supabase_get("/rest/v1/kstartup_announcements?select=announcement_id")
    return {r["announcement_id"] for r in rows}


# ---------------------------------------------------------------------------
# 3. K-Startup ê³µê³  ëª©ë¡ ìˆ˜ì§‘
# ---------------------------------------------------------------------------

def fetch_announcements() -> list:
    """K-Startup ì§„í–‰ ì¤‘ ì‚¬ì—…ê³µê³  ëª©ë¡ ìˆ˜ì§‘."""
    announcements = []

    # ë°©ë²• A: AJAX API ì‹œë„
    announcements = _try_ajax_api()

    # ë°©ë²• B: HTML íŒŒì‹± fallback
    if not announcements:
        announcements = _try_html_parse()

    return announcements


def _try_ajax_api() -> list:
    """AJAX APIë¡œ ê³µê³  ëª©ë¡ ìˆ˜ì§‘ ì‹œë„."""
    results = []
    params = {
        "pbancEndYn": "N",
        "pageIndex": "1",
        "pageUnit": "50",
        "orderby": "REG_DT_DESC",
    }

    for url in [KSTARTUP_API_URL, KSTARTUP_LIST_URL]:
        try:
            resp = requests.post(
                url,
                data=params,
                headers={**SESSION_HEADERS, "X-Requested-With": "XMLHttpRequest"},
                timeout=20,
            )
            if resp.status_code != 200:
                continue

            # JSON ì‘ë‹µ ì‹œë„
            try:
                data = resp.json()
                items = data.get("list") or data.get("data") or data.get("resultList") or []
                if items:
                    for item in items:
                        ann = _parse_dict_item(item)
                        if ann:
                            results.append(ann)
                    if results:
                        print(f"  AJAX APIì—ì„œ {len(results)}ê°œ ìˆ˜ì§‘ (JSON)")
                        return results
            except ValueError:
                pass

            # HTML ì‘ë‹µ ì‹œë„
            soup = BeautifulSoup(resp.text, "html.parser")
            items = soup.select("li.card-item, .biz-card, li[data-pbanc-sn]")
            if not items:
                items = soup.select("table tbody tr")
            for item in items:
                ann = _parse_html_item(item)
                if ann:
                    results.append(ann)
            if results:
                print(f"  AJAXì—ì„œ {len(results)}ê°œ ìˆ˜ì§‘ (HTML)")
                return results

        except Exception as e:
            print(f"  AJAX ì‹œë„ ì‹¤íŒ¨ ({url}): {e}", file=sys.stderr)

    return results


def _try_html_parse() -> list:
    """ë©”ì¸ ëª©ë¡ í˜ì´ì§€ HTML íŒŒì‹±."""
    results = []
    try:
        resp = requests.get(KSTARTUP_LIST_URL, headers=SESSION_HEADERS, timeout=20)
        soup = BeautifulSoup(resp.text, "html.parser")

        selectors = [
            "li.card-item", ".biz-card", "li[data-pbanc-sn]",
            ".list-wrap li", "table tbody tr",
        ]
        for sel in selectors:
            items = soup.select(sel)
            if items:
                for item in items:
                    ann = _parse_html_item(item)
                    if ann:
                        results.append(ann)
                if results:
                    print(f"  HTML({sel})ì—ì„œ {len(results)}ê°œ ìˆ˜ì§‘")
                    break

    except Exception as e:
        print(f"  HTML íŒŒì‹± ì‹¤íŒ¨: {e}", file=sys.stderr)

    return results


def _parse_dict_item(item: dict) -> dict | None:
    """JSON ë”•ì…”ë„ˆë¦¬ì—ì„œ ê³µê³  ì •ë³´ íŒŒì‹±."""
    ann_id = (
        str(item.get("pbancSn") or item.get("PBANC_SN") or
            item.get("id") or item.get("ID") or "")
    )
    if not ann_id:
        return None

    title = (
        item.get("pbancNm") or item.get("PBANC_NM") or
        item.get("title") or item.get("TITLE") or ""
    )
    deadline = (
        item.get("pbancRqstEndDe") or item.get("PBANC_RQST_END_DE") or
        item.get("endDate") or ""
    )

    return {
        "announcement_id": ann_id,
        "title": title.strip(),
        "url": f"{KSTARTUP_LIST_URL}?pbancSn={ann_id}",
        "deadline": deadline,
    }


def _parse_html_item(item) -> dict | None:
    """BeautifulSoup ìš”ì†Œì—ì„œ ê³µê³  ì •ë³´ íŒŒì‹±."""
    # ID ì¶”ì¶œ
    ann_id = item.get("data-pbanc-sn") or item.get("data-seq") or ""

    if not ann_id:
        link = item.find("a", href=True)
        if link:
            href = link["href"]
            m = re.search(r"pbancSn=(\d+)", href)
            if m:
                ann_id = m.group(1)
            else:
                m2 = re.search(r"[?&](?:seq|id|sn)=(\d+)", href, re.I)
                if m2:
                    ann_id = m2.group(1)

    if not ann_id:
        # onclickì—ì„œ ID ì¶”ì¶œ ì‹œë„
        elem = item.find(attrs={"onclick": True})
        if elem:
            m = re.search(r"(\d{4,})", elem.get("onclick", ""))
            if m:
                ann_id = m.group(1)

    if not ann_id:
        return None

    # ì œëª©
    title_elem = (
        item.find(class_=re.compile(r"title|subject|name|tit", re.I)) or
        item.find("strong") or
        item.find("a")
    )
    title = title_elem.get_text(strip=True) if title_elem else item.get_text(strip=True)[:80]

    # ë§ˆê°ì¼
    date_elems = item.find_all(class_=re.compile(r"date|period|end|due", re.I))
    deadline = date_elems[-1].get_text(strip=True) if date_elems else ""

    return {
        "announcement_id": str(ann_id),
        "title": title,
        "url": f"{KSTARTUP_LIST_URL}?pbancSn={ann_id}",
        "deadline": deadline,
    }


# ---------------------------------------------------------------------------
# 4. ê³µê³  ìƒì„¸ í˜ì´ì§€ ìˆ˜ì§‘
# ---------------------------------------------------------------------------

def fetch_announcement_detail(url: str) -> dict:
    """ê³µê³  ìƒì„¸ í˜ì´ì§€ì—ì„œ ë‚´ìš© í…ìŠ¤íŠ¸ ë° ì²¨ë¶€íŒŒì¼ ë§í¬ ì¶”ì¶œ."""
    result = {"content": "", "pdf_urls": [], "apply_urls": []}

    try:
        resp = requests.get(url, headers=SESSION_HEADERS, timeout=20)
        soup = BeautifulSoup(resp.text, "html.parser")

        # ë³¸ë¬¸ í…ìŠ¤íŠ¸
        body = soup.find(class_=re.compile(r"view|content|detail|body", re.I))
        if body:
            result["content"] = body.get_text(separator="\n", strip=True)[:5000]

        # ì²¨ë¶€íŒŒì¼ ë§í¬
        for link in soup.find_all("a", href=True):
            href = link["href"]
            text = link.get_text(strip=True)

            is_file = (
                ".pdf" in href.lower() or
                "fileDown" in href or
                "download" in href.lower() or
                "atchFile" in href or
                ".hwp" in href.lower()
            )
            if not is_file:
                continue

            full_url = href if href.startswith("http") else f"{KSTARTUP_BASE}{href}"

            apply_keywords = ["ì‹ ì²­ì„œ", "ì„œì‹", "ì–‘ì‹", "ì§€ì›ì„œ", "ì‹ ì²­ì–‘ì‹", "ì„œë¥˜"]
            if any(kw in text for kw in apply_keywords):
                result["apply_urls"].append({"url": full_url, "name": text})
            else:
                result["pdf_urls"].append({"url": full_url, "name": text})

    except Exception as e:
        print(f"  ìƒì„¸ í˜ì´ì§€ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨ ({url}): {e}", file=sys.stderr)

    return result


# ---------------------------------------------------------------------------
# 5. PDF/HWP í…ìŠ¤íŠ¸ ì¶”ì¶œ
# ---------------------------------------------------------------------------

def download_and_extract_text(url: str) -> str:
    """PDF íŒŒì¼ ë‹¤ìš´ë¡œë“œ í›„ í…ìŠ¤íŠ¸ ì¶”ì¶œ. HWPëŠ” í…ìŠ¤íŠ¸ ì¶”ì¶œ ë¶ˆê°€ë¡œ ê±´ë„ˆëœ€."""
    if ".hwp" in url.lower():
        return ""  # HWPëŠ” ë³„ë„ íŒŒì„œ í•„ìš” â€” í˜„ì¬ ë¯¸ì§€ì›

    try:
        resp = requests.get(url, headers=SESSION_HEADERS, timeout=60)
        if resp.status_code != 200:
            return ""

        reader = pypdf.PdfReader(BytesIO(resp.content))
        pages = []
        for page in reader.pages[:20]:
            text = page.extract_text() or ""
            pages.append(text)

        return "\n".join(pages)[:8000]

    except Exception as e:
        print(f"  PDF ì¶”ì¶œ ì‹¤íŒ¨ ({url[:60]}): {e}", file=sys.stderr)
        return ""


# ---------------------------------------------------------------------------
# 6. Claude ì í•©ì„± ë¶„ì„
# ---------------------------------------------------------------------------

def analyze_eligibility(
    announcement: dict,
    pdf_text: str,
    page_content: str,
    user_profile: dict,
) -> dict:
    """Claudeë¡œ ìê²©ìš”ê±´ ë¶„ì„ ë° ê¸°ì—… í”„ë¡œí•„ê³¼ ì í•©ì„± íŒë‹¨."""
    client = anthropic.Anthropic()

    profile_text = json.dumps(user_profile, ensure_ascii=False, indent=2)
    content = (pdf_text or page_content or "ê³µê³  ë‚´ìš©ì„ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")[:6000]

    prompt = f"""ë‹¹ì‹ ì€ ì°½ì—… ì§€ì› ì‚¬ì—… ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì•„ë˜ì˜ ì‚¬ì—…ê³µê³  ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬, ì£¼ì–´ì§„ ê¸°ì—… í”„ë¡œí•„ì´ ì§€ì› ìê²©ì„ ê°–ì¶”ê³  ìˆëŠ”ì§€ íŒë‹¨í•´ì£¼ì„¸ìš”.

## ì‚¬ì—… ê³µê³ ëª…
{announcement['title']}

## ê¸°ì—… í”„ë¡œí•„
{profile_text}

## ê³µê³  ë‚´ìš©
{content}

## ë¶„ì„ ìš”ì²­
1. í•µì‹¬ ì§€ì› ìê²© ìš”ê±´ì„ 3~5ê°œ ì¶”ì¶œí•˜ì„¸ìš”.
2. ê¸°ì—… í”„ë¡œí•„ì˜ ê° ìš”ê±´ ì¶©ì¡± ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ì„¸ìš” (ì¶©ì¡±/ë¯¸ì¶©ì¡±/ë¶ˆëª…í™•).
3. ì¢…í•©ì ì¸ ì§€ì› ê°€ëŠ¥ ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ì„¸ìš”.
4. í•œ ì¤„ ìš”ì•½ì„ ì‘ì„±í•˜ì„¸ìš”.

ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš” (ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì—†ì´):
{{
  "requirements": [
    {{"condition": "ìš”ê±´ ì„¤ëª…", "status": "ì¶©ì¡±", "reason": "íŒë‹¨ ê·¼ê±°"}}
  ],
  "eligible": true,
  "summary": "ìµœì¢… íŒë‹¨ í•œ ì¤„ ìš”ì•½"
}}

eligible ê°’: true(ì§€ì› ê°€ëŠ¥), false(ì§€ì› ë¶ˆê°€), null(ì •ë³´ ë¶€ì¡±ìœ¼ë¡œ ë¶ˆëª…í™•)"""

    try:
        message = client.messages.create(
            model="claude-opus-4-5",
            max_tokens=1500,
            messages=[{"role": "user", "content": prompt}],
        )
        text = message.content[0].text.strip()

        # JSON íŒŒì‹±
        m = re.search(r"\{[\s\S]*\}", text)
        if m:
            return json.loads(m.group())
        return {"eligible": None, "summary": text[:300], "requirements": []}

    except Exception as e:
        print(f"  ì í•©ì„± ë¶„ì„ ì˜¤ë¥˜: {e}", file=sys.stderr)
        return {"eligible": None, "summary": f"ë¶„ì„ ì˜¤ë¥˜: {e}", "requirements": []}


# ---------------------------------------------------------------------------
# 7. Claude ì‹ ì²­ì„œ ì´ˆì•ˆ ì‘ì„±
# ---------------------------------------------------------------------------

def draft_application(
    announcement: dict,
    apply_text: str,
    pdf_text: str,
    user_profile: dict,
) -> str:
    """ì í•©í•œ ê³µê³ ì— ëŒ€í•´ Claudeë¡œ ì‹ ì²­ì„œ ì´ˆì•ˆ ì‘ì„±."""
    client = anthropic.Anthropic()

    profile_text = json.dumps(user_profile, ensure_ascii=False, indent=2)

    prompt = f"""ë‹¹ì‹ ì€ ì°½ì—… ì§€ì› ì‚¬ì—… ì‹ ì²­ì„œ ì‘ì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì•„ë˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹ ì²­ì„œ ì´ˆì•ˆì„ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
ì‹¤ì œ ë°ì´í„°ê°€ ì—†ëŠ” í•­ëª©ì€ [í™•ì¸ í•„ìš”: í•­ëª©ëª…] í˜•íƒœë¡œ í‘œì‹œí•˜ì„¸ìš”.

## ê³µê³ ëª…
{announcement['title']}

## ê¸°ì—… í”„ë¡œí•„
{profile_text}

## ì‚¬ì—… ê°œìš” (ê³µê³  PDF ìš”ì•½)
{pdf_text[:2500] if pdf_text else "(ê³µê³  PDF ì—†ìŒ)"}

## ì‹ ì²­ ì–‘ì‹ ë‚´ìš©
{apply_text[:2500] if apply_text else "(ì–‘ì‹ íŒŒì¼ ì—†ìŒ - ì¼ë°˜ ì°½ì—…ì§€ì› ì‹ ì²­ì„œ í˜•ì‹ìœ¼ë¡œ ì‘ì„±)"}

---

ë‹¤ìŒ í•­ëª©ì„ ëª¨ë‘ í¬í•¨í•œ ì‹ ì²­ì„œ ì´ˆì•ˆì„ ì‘ì„±í•˜ì„¸ìš”:

# ì‚¬ì—… ì‹ ì²­ì„œ ì´ˆì•ˆ â€” {announcement['title']}

## 1. ì‹ ì²­ ê¸°ì—… í˜„í™©
(ê¸°ì—…ëª…, ì„¤ë¦½ì¼, ì—…ì¢…, ì£¼ìš” ì œí’ˆ/ì„œë¹„ìŠ¤, ëŒ€í‘œì ë“±)

## 2. ì‹ ì²­ ëª©ì  ë° ì‚¬ì—… ì´í•´ë„
(ì´ ì‚¬ì—…ì— ì§€ì›í•˜ëŠ” ì´ìœ , ì‚¬ì—… ëª©í‘œì™€ì˜ ì—°ê´€ì„±)

## 3. ì§€ì›ê¸ˆ/í”„ë¡œê·¸ë¨ í™œìš© ê³„íš
(êµ¬ì²´ì ì¸ í™œìš© ë°©ì•ˆ, ì¼ì • ë“±)

## 4. ê¸°ëŒ€ íš¨ê³¼
(ì •ëŸ‰ì /ì •ì„±ì  ê¸°ëŒ€ ì„±ê³¼)

## 5. í–¥í›„ ì„±ì¥ ê³„íš
(ì¤‘ì¥ê¸° ë°œì „ ë°©í–¥)"""

    try:
        message = client.messages.create(
            model="claude-opus-4-5",
            max_tokens=3000,
            messages=[{"role": "user", "content": prompt}],
        )
        return message.content[0].text

    except Exception as e:
        print(f"  ì´ˆì•ˆ ì‘ì„± ì˜¤ë¥˜: {e}", file=sys.stderr)
        return f"ì´ˆì•ˆ ì‘ì„± ì‹¤íŒ¨: {e}"


# ---------------------------------------------------------------------------
# 8. Supabase ì €ì¥
# ---------------------------------------------------------------------------

def save_announcement(announcement: dict, analysis: dict, draft: str = "") -> bool:
    return _supabase_post(
        "/rest/v1/kstartup_announcements",
        {
            "announcement_id": announcement["announcement_id"],
            "title": announcement["title"],
            "url": announcement["url"],
            "deadline": announcement.get("deadline", ""),
            "eligible": analysis.get("eligible"),
            "analysis": json.dumps(analysis, ensure_ascii=False),
            "draft": draft,
            "created_at": datetime.now(KST).isoformat(),
        },
    )


# ---------------------------------------------------------------------------
# 9. í…”ë ˆê·¸ë¨ ì•Œë¦¼
# ---------------------------------------------------------------------------

def send_telegram(
    token: str,
    chat_id: str,
    announcement: dict,
    analysis: dict,
    draft: str = "",
) -> bool:
    eligible = analysis.get("eligible")
    if eligible is True:
        status = "âœ… ì§€ì› ê°€ëŠ¥"
    elif eligible is False:
        status = "âŒ ì§€ì› ë¶ˆê°€"
    else:
        status = "â“ ê²€í†  í•„ìš”"

    summary = analysis.get("summary", "")[:300]
    reqs = analysis.get("requirements", [])

    req_lines = ""
    for r in reqs[:4]:
        icon = {"ì¶©ì¡±": "âœ…", "ë¯¸ì¶©ì¡±": "âŒ"}.get(r.get("status", ""), "â“")
        req_lines += f"{icon} {r.get('condition', '')[:50]}\n"

    msg = (
        f"<b>ğŸ“¢ K-Startup ìƒˆ ê³µê³ </b>\n\n"
        f"<b>ì‚¬ì—…ëª…:</b> {announcement['title'][:80]}\n"
        f"<b>ë§ˆê°:</b> {announcement.get('deadline', 'ë¯¸ìƒ')}\n"
        f"<b>ë§í¬:</b> {announcement['url']}\n\n"
        f"<b>ì í•©ì„±:</b> {status}\n"
        f"<b>ìš”ì•½:</b> {summary}\n"
    )
    if req_lines:
        msg += f"\n<b>ìê²© ìš”ê±´:</b>\n{req_lines}"
    if draft:
        msg += f"\n<b>ğŸ“ ì‹ ì²­ì„œ ì´ˆì•ˆ ì‘ì„± ì™„ë£Œ</b> (Supabase ì €ì¥ë¨)\n"

    payload = json.dumps({
        "chat_id": chat_id,
        "text": msg,
        "parse_mode": "HTML",
        "disable_web_page_preview": True,
    }).encode("utf-8")

    req = urllib.request.Request(
        f"https://api.telegram.org/bot{token}/sendMessage",
        data=payload,
        headers={"Content-Type": "application/json"},
        method="POST",
    )
    try:
        with urllib.request.urlopen(req, timeout=15) as resp:
            result = json.loads(resp.read().decode())
            if result.get("ok"):
                print("  í…”ë ˆê·¸ë¨ ë°œì†¡ ì™„ë£Œ")
                return True
            print(f"  í…”ë ˆê·¸ë¨ ì‹¤íŒ¨: {result}", file=sys.stderr)
            return False
    except Exception as e:
        print(f"  í…”ë ˆê·¸ë¨ ì˜¤ë¥˜: {e}", file=sys.stderr)
        return False


def send_telegram_summary(token: str, chat_id: str, message: str) -> None:
    """ê°„ë‹¨í•œ ìš”ì•½ ë©”ì‹œì§€ë¥¼ í…”ë ˆê·¸ë¨ìœ¼ë¡œ ë°œì†¡."""
    payload = json.dumps({
        "chat_id": chat_id,
        "text": message,
        "parse_mode": "HTML",
        "disable_web_page_preview": True,
    }).encode("utf-8")

    req = urllib.request.Request(
        f"https://api.telegram.org/bot{token}/sendMessage",
        data=payload,
        headers={"Content-Type": "application/json"},
        method="POST",
    )
    try:
        with urllib.request.urlopen(req, timeout=15) as resp:
            result = json.loads(resp.read().decode())
            if result.get("ok"):
                print("  í…”ë ˆê·¸ë¨ ìš”ì•½ ë°œì†¡ ì™„ë£Œ")
            else:
                print(f"  í…”ë ˆê·¸ë¨ ìš”ì•½ ì‹¤íŒ¨: {result}", file=sys.stderr)
    except Exception as e:
        print(f"  í…”ë ˆê·¸ë¨ ìš”ì•½ ì˜¤ë¥˜: {e}", file=sys.stderr)




def main():
    print("=== K-Startup ì‚¬ì—…ê³µê³  ëª¨ë‹ˆí„°ë§ ì—ì´ì „íŠ¸ ì‹œì‘ ===\n")

    # 1. ì‚¬ìš©ì í”„ë¡œí•„
    print("[1/5] ì‚¬ìš©ì í”„ë¡œí•„ ë¡œë“œ ì¤‘...")
    user_profile = load_user_profile()
    if not user_profile:
        print("  ê²½ê³ : í”„ë¡œí•„ ì—†ì´ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤. ì í•©ì„± ë¶„ì„ì´ ë¶€ì •í™•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    # 2. ê¸°ì¡´ ì²˜ë¦¬ ê³µê³  ID
    print("\n[2/5] ê¸°ì¡´ ê³µê³  ëª©ë¡ ë¡œë“œ ì¤‘...")
    seen_ids = get_seen_ids()
    print(f"  ê¸°ì¡´ ì²˜ë¦¬ ê³µê³ : {len(seen_ids)}ê°œ")

    # 3. ìƒˆ ê³µê³  ìˆ˜ì§‘
    print("\n[3/5] K-Startup ì‚¬ì—…ê³µê³  ìˆ˜ì§‘ ì¤‘...")
    all_anns = fetch_announcements()
    print(f"  ìˆ˜ì§‘ëœ ê³µê³ : {len(all_anns)}ê°œ")

    new_anns = [a for a in all_anns if a["announcement_id"] not in seen_ids]
    print(f"  ìƒˆ ê³µê³ : {len(new_anns)}ê°œ")

    # 4. í…”ë ˆê·¸ë¨ í† í° ì„¤ì •
    token = os.environ.get("TELEGRAM_BOT_TOKEN", "")
    chat_id = os.environ.get("TELEGRAM_CHAT_ID", "")

    if not all_anns:
        msg = (
            f"<b>ğŸ“¢ K-Startup ëª¨ë‹ˆí„°ë§ ê²°ê³¼</b>\n\n"
            f"âš ï¸ ì‚¬ì´íŠ¸ì—ì„œ ê³µê³ ë¥¼ ìˆ˜ì§‘í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\n"
            f"K-Startup ì‚¬ì´íŠ¸ êµ¬ì¡°ê°€ ë³€ê²½ë˜ì—ˆê±°ë‚˜ ì¼ì‹œì  ì˜¤ë¥˜ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        )
        if token and chat_id:
            send_telegram_summary(token, chat_id, msg)
        print("\nK-Startupì—ì„œ ê³µê³ ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    if not new_anns:
        msg = (
            f"<b>ğŸ“¢ K-Startup ëª¨ë‹ˆí„°ë§ ê²°ê³¼</b>\n\n"
            f"âœ… ì—ì´ì „íŠ¸ ì •ìƒ ì‹¤í–‰ ì™„ë£Œ\n"
            f"ì „ì²´ ê³µê³ : {len(all_anns)}ê°œ | ìƒˆ ê³µê³ : 0ê°œ\n"
            f"(ëª¨ë‘ ì´ë¯¸ ì²˜ë¦¬ëœ ê³µê³ ì…ë‹ˆë‹¤)"
        )
        if token and chat_id:
            send_telegram_summary(token, chat_id, msg)
        print("\nìƒˆë¡œìš´ ê³µê³ ê°€ ì—†ìŠµë‹ˆë‹¤. ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    print(f"\n[4/5] ìƒˆ ê³µê³  {len(new_anns)}ê°œ ë¶„ì„ ì¤‘...")

    eligible_count = 0
    for i, ann in enumerate(new_anns, 1):
        print(f"\n  [{i}/{len(new_anns)}] {ann['title'][:60]}...")

        # ìƒì„¸ í˜ì´ì§€
        detail = fetch_announcement_detail(ann["url"])

        # PDF í…ìŠ¤íŠ¸ ìˆ˜ì§‘ (ê³µê³ ë¬¸, ìµœëŒ€ 2ê°œ)
        pdf_text = ""
        for pdf_info in detail["pdf_urls"][:2]:
            print(f"    PDF ë‹¤ìš´ë¡œë“œ: {pdf_info['name'][:40]}")
            t = download_and_extract_text(pdf_info["url"])
            if t:
                pdf_text += t + "\n\n"

        # ì í•©ì„± ë¶„ì„
        print("    ì í•©ì„± ë¶„ì„ ì¤‘...")
        analysis = analyze_eligibility(ann, pdf_text, detail["content"], user_profile)
        eligible = analysis.get("eligible")
        label = "ì§€ì› ê°€ëŠ¥ âœ…" if eligible is True else "ì§€ì› ë¶ˆê°€ âŒ" if eligible is False else "ê²€í†  í•„ìš” â“"
        print(f"    ê²°ê³¼: {label}")

        # ì‹ ì²­ì„œ ì´ˆì•ˆ (ì í•©í•œ ê²½ìš°)
        draft = ""
        if eligible is True:
            eligible_count += 1
            print("    ì‹ ì²­ì„œ ì´ˆì•ˆ ì‘ì„± ì¤‘...")
            apply_text = ""
            for apply_info in detail["apply_urls"][:1]:
                apply_text = download_and_extract_text(apply_info["url"])
            draft = draft_application(ann, apply_text, pdf_text, user_profile)

        # ì €ì¥ & ì•Œë¦¼
        save_announcement(ann, analysis, draft)
        if token and chat_id:
            send_telegram(token, chat_id, ann, analysis, draft)

        if i < len(new_anns):
            time.sleep(2)

    print(f"\n[5/5] ì™„ë£Œ")
    print(f"  ì²˜ë¦¬: {len(new_anns)}ê°œ | ì§€ì› ê°€ëŠ¥: {eligible_count}ê°œ")

    if token and chat_id:
        summary_msg = (
            f"<b>ğŸ“Š K-Startup ë¶„ì„ ì™„ë£Œ</b>\n\n"
            f"ì „ì²´ ê³µê³ : {len(all_anns)}ê°œ\n"
            f"ìƒˆ ê³µê³ : {len(new_anns)}ê°œ ì²˜ë¦¬\n"
            f"ì§€ì› ê°€ëŠ¥: {eligible_count}ê°œ"
        )
        send_telegram_summary(token, chat_id, summary_msg)


if __name__ == "__main__":
    main()
