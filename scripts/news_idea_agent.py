#!/usr/bin/env python3
"""
ë‰´ìŠ¤ ì•„ì´ë””ì–´ ì—ì´ì „íŠ¸
- ë§¤ ì‹œê°„ ì •ê° GitHub Actionsì— ì˜í•´ ìë™ ì‹¤í–‰
- Supabase agent_settings í…Œì´ë¸”ì—ì„œ ì„¤ì • ë¡œë“œ
- í™œì„±í™”ëœ í•œêµ­ ë‰´ìŠ¤ RSS í”¼ë“œì—ì„œ ë‰´ìŠ¤ 3ê°œ ìˆ˜ì§‘
- Claude AIë¡œ 3ê°œ ë‰´ìŠ¤ë¥¼ ê²°í•©í•˜ì—¬ ìƒˆë¡œìš´ ì•„ì´ë””ì–´ ë„ì¶œ
- Supabaseì— ì €ì¥ + í…”ë ˆê·¸ë¨ìœ¼ë¡œ ë°œì†¡
"""

import os
import re
import sys
import json
import socket
import hashlib
import feedparser
import anthropic
import urllib.request
import urllib.parse
from datetime import datetime, timezone, timedelta


ALL_SOURCES = {
    # Google News (í•´ì™¸ ì„œë²„ì—ì„œë„ ì•ˆì •ì ìœ¼ë¡œ ì ‘ê·¼ ê°€ëŠ¥ â€” ìµœìš°ì„  ì‹œë„)
    "êµ¬ê¸€ë‰´ìŠ¤": "https://news.google.com/rss?hl=ko&gl=KR&ceid=KR:ko",
    "êµ¬ê¸€ë‰´ìŠ¤_ê²½ì œ": "https://news.google.com/rss/topics/CAAqJggKIiBDQkFTRWdvSUwyMHZNRGx6TVdZU0FtdHZHZ0pMVWlnQVAB?hl=ko&gl=KR&ceid=KR:ko",
    "êµ¬ê¸€ë‰´ìŠ¤_IT": "https://news.google.com/rss/topics/CAAqJggKIiBDQkFTRWdvSUwyMHZNRGd3TVRBU0FtdHZHZ0pMVWlnQVAB?hl=ko&gl=KR&ceid=KR:ko",
    # ë°©ì†¡ì‚¬
    "KBS":    "https://news.kbs.co.kr/rss/rss.do",
    "MBC":    "https://imnews.imbc.com/rss/news/news_00.xml",
    "SBS":    "https://news.sbs.co.kr/news/headlineRssFeed.do?plink=RSSREADER",
    "JTBC":   "https://news.jtbc.co.kr/RSS/NewsFlash.xml",
    # í†µì‹ ì‚¬
    "ì—°í•©ë‰´ìŠ¤":  "https://www.yna.co.kr/RSS/news.xml",
    "ë‰´ìŠ¤1":   "https://www.news1.kr/rss/allNews.xml",
    "ë‰´ì‹œìŠ¤":  "https://www.newsis.com/RSS/",
    # ì¢…í•©ì¼ê°„ì§€
    "ì¡°ì„ ì¼ë³´": "https://www.chosun.com/arc/outboundfeeds/rss/?outputType=xml",
    "ì¤‘ì•™ì¼ë³´": "https://rss.joinsmsn.com/news/sectlist/uAll.xml",
    "ë™ì•„ì¼ë³´": "https://rss.donga.com/total.xml",
    "í•œê²¨ë ˆ":  "https://www.hani.co.kr/rss/",
    "ê²½í–¥ì‹ ë¬¸": "https://www.khan.co.kr/rss/rssdata/total_news.xml",
    # ê²½ì œì§€
    "ë§¤ì¼ê²½ì œ": "https://www.mk.co.kr/rss/30000001/",
    "í•œêµ­ê²½ì œ": "https://www.hankyung.com/feed/all-news",
    "ë¨¸ë‹ˆíˆ¬ë°ì´": "https://rss.mt.co.kr/rss/mt_news.xml",
    # ìŠ¤íƒ€íŠ¸ì—…
    "ì¼€ì´ìŠ¤íƒ€íŠ¸ì—…": "https://www.k-startup.go.kr/web/contents/rss/startupnews.do",
}

# GitHub Actions í™˜ê²½ì—ì„œë„ í•­ìƒ ì ‘ê·¼ ê°€ëŠ¥í•œ ë³´ì¥ ì†ŒìŠ¤
GUARANTEED_SOURCES = ["êµ¬ê¸€ë‰´ìŠ¤", "êµ¬ê¸€ë‰´ìŠ¤_ê²½ì œ", "êµ¬ê¸€ë‰´ìŠ¤_IT"]

DEFAULT_PROMPT_TEMPLATE = """ë‹¹ì‹ ì€ ì°½ì˜ì ì¸ ì•„ì´ë””ì–´ ê¸°íšìì…ë‹ˆë‹¤.
ì•„ë˜ ì˜¤ëŠ˜ì˜ ì£¼ìš” ë‰´ìŠ¤ë“¤ì„ ê¹Šì´ ë¶„ì„í•˜ê³ , ì´ ë‰´ìŠ¤ë“¤ì˜ íë¦„ì„ ì°½ì˜ì ìœ¼ë¡œ ê²°í•©í•˜ì—¬ í˜ì‹ ì ì¸ ìƒˆë¡œìš´ ì•„ì´ë””ì–´ë¥¼ í•˜ë‚˜ ë„ì¶œí•´ì£¼ì„¸ìš”.

{news_block}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì•„ì´ë””ì–´ë¥¼ ì œì‹œí•´ì£¼ì„¸ìš”:

## ì•„ì´ë””ì–´ ì´ë¦„
(ê°„ê²°í•˜ê³  ì¸ìƒì ì¸ ì´ë¦„)

## í•µì‹¬ í†µì°°
(ë‰´ìŠ¤ë“¤ì´ ì–´ë–¤ ê³µí†µëœ íë¦„ì´ë‚˜ ê¸°íšŒë¥¼ ê°€ë¦¬í‚¤ëŠ”ì§€ ì„¤ëª…)

## ì•„ì´ë””ì–´ ì„¤ëª…
(êµ¬ì²´ì ì¸ ì„œë¹„ìŠ¤/ì œí’ˆ/ì •ì±…/ìº í˜ì¸ ì•„ì´ë””ì–´)

## ì‹¤í˜„ ë°©ì•ˆ
(ë‹¨ê³„ë³„ ì ‘ê·¼ë²• ë˜ëŠ” ì£¼ìš” ì‹¤í–‰ í¬ì¸íŠ¸ 3ê°€ì§€)

## ê¸°ëŒ€ íš¨ê³¼
(ì´ ì•„ì´ë””ì–´ê°€ ê°€ì ¸ì˜¬ ë³€í™”ì™€ ê°€ì¹˜)

[ì£¼ì˜ì‚¬í•­]
- í‘œ(í…Œì´ë¸”) í˜•ì‹ì„ ì‚¬ìš©í•˜ì§€ ë§ê³  ê¸€ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
- ë‰´ìŠ¤ ì›ë¬¸ ë§í¬ì™€ ì´ë¯¸ì§€ëŠ” ì‹œìŠ¤í…œì—ì„œ ìë™ìœ¼ë¡œ ì²¨ë¶€ë©ë‹ˆë‹¤. ì§ì ‘ ë§í¬ë‚˜ ì´ë¯¸ì§€ ì„¤ëª…ì„ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”.
- ìœ„ì˜ 5ê°œ ì„¹ì…˜ë§Œ ì‘ì„±í•˜ì„¸ìš”."""

KST = timezone(timedelta(hours=9))


def _supabase_headers() -> dict:
    key = os.environ.get("SUPABASE_SERVICE_ROLE_KEY", "")
    return {
        "apikey": key,
        "Authorization": f"Bearer {key}",
        "Content-Type": "application/json",
    }


# ---------------------------------------------------------------------------
# 0. ì„¤ì • ë¡œë“œ
# ---------------------------------------------------------------------------

def fetch_settings() -> dict:
    """Supabase agent_settings í…Œì´ë¸”ì—ì„œ ì„¤ì • ë¡œë“œ. ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜."""
    default = {
        "enabled": True,
        "run_every_hours": 1,
        "active_sources": list(ALL_SOURCES.keys()),
        "prompt_template": "",
    }

    url = os.environ.get("SUPABASE_URL", "").rstrip("/")
    key = os.environ.get("SUPABASE_SERVICE_ROLE_KEY", "")

    if not url or not key:
        return default

    req = urllib.request.Request(
        f"{url}/rest/v1/agent_settings?id=eq.1",
        headers=_supabase_headers(),
    )
    try:
        with urllib.request.urlopen(req) as resp:
            data = json.loads(resp.read().decode())
            if data:
                return {**default, **data[0]}
    except Exception as e:
        print(f"ì„¤ì • ë¡œë“œ ì‹¤íŒ¨ (ê¸°ë³¸ê°’ ì‚¬ìš©): {e}", file=sys.stderr)

    return default


# ---------------------------------------------------------------------------
# 1. ë‰´ìŠ¤ ìˆ˜ì§‘
# ---------------------------------------------------------------------------

_BROWSER_UA = (
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
    "AppleWebKit/537.36 (KHTML, like Gecko) "
    "Chrome/124.0.0.0 Safari/537.36"
)


def _extract_image_url(entry) -> str:
    """RSS í•­ëª©ì—ì„œ ì‹¤ì œ ì´ë¯¸ì§€ URL ì¶”ì¶œ (media_thumbnail â†’ media_content â†’ enclosures ìˆœ)."""
    for thumb in entry.get("media_thumbnail", []):
        if thumb.get("url"):
            return thumb["url"]
    for media in entry.get("media_content", []):
        url = media.get("url", "")
        if url and "image" in media.get("type", "image"):
            return url
    for enc in entry.get("enclosures", []):
        if "image" in enc.get("type", "") and (enc.get("href") or enc.get("url")):
            return enc.get("href") or enc.get("url", "")
    return ""


def _resolve_google_news_url(url: str) -> str:
    """Google News URL â†’ ì‹¤ì œ ê¸°ì‚¬ URL (HTTP ë¦¬ë””ë ‰ì…˜ ì¶”ì , ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°˜í™˜)."""
    if "news.google.com" not in url:
        return url
    try:
        req = urllib.request.Request(url, headers={"User-Agent": _BROWSER_UA})
        with urllib.request.urlopen(req, timeout=10) as resp:
            final = resp.url
            return final if "news.google.com" not in final else url
    except Exception as e:
        print(f"    Google URL ë³€í™˜ ì‹¤íŒ¨: {e}", file=sys.stderr)
        return url


def _download_image(image_url: str) -> tuple:
    """ì´ë¯¸ì§€ URLì—ì„œ ë°”ì´ë„ˆë¦¬ ë°ì´í„° ë‹¤ìš´ë¡œë“œ. (bytes, content_type) ë°˜í™˜. ì‹¤íŒ¨ ì‹œ (b'', '')."""
    if not image_url:
        return b"", ""
    try:
        req = urllib.request.Request(image_url, headers={"User-Agent": _BROWSER_UA})
        with urllib.request.urlopen(req, timeout=15) as resp:
            ct = resp.headers.get("Content-Type", "image/jpeg").split(";")[0].strip()
            if not ct.startswith("image/"):
                return b"", ""
            return resp.read(), ct
    except Exception as e:
        print(f"    ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ({image_url[:70]}): {e}", file=sys.stderr)
        return b"", ""


def _ensure_supabase_bucket(bucket: str) -> bool:
    """Supabase Storage ë²„í‚·ì´ ì—†ìœ¼ë©´ public ë²„í‚·ìœ¼ë¡œ ìƒì„±."""
    supa_url = os.environ.get("SUPABASE_URL", "").rstrip("/")
    key = os.environ.get("SUPABASE_SERVICE_ROLE_KEY", "")
    if not supa_url or not key:
        return False
    headers = {"apikey": key, "Authorization": f"Bearer {key}"}
    try:
        req = urllib.request.Request(f"{supa_url}/storage/v1/bucket/{bucket}", headers=headers)
        urllib.request.urlopen(req, timeout=10)
        return True  # ì´ë¯¸ ì¡´ì¬
    except urllib.error.HTTPError as e:
        if e.code not in (400, 404):
            return False
    except Exception:
        return False
    # ë²„í‚· ìƒì„±
    payload = json.dumps({"id": bucket, "name": bucket, "public": True}).encode()
    req2 = urllib.request.Request(
        f"{supa_url}/storage/v1/bucket",
        data=payload,
        headers={**headers, "Content-Type": "application/json"},
        method="POST",
    )
    try:
        urllib.request.urlopen(req2, timeout=10)
        print(f"  Supabase ë²„í‚· '{bucket}' ìƒì„± ì™„ë£Œ")
        return True
    except Exception as e:
        print(f"  Supabase ë²„í‚· ìƒì„± ì‹¤íŒ¨: {e}", file=sys.stderr)
        return False


def _upload_image_to_supabase(image_data: bytes, filename: str, content_type: str) -> str:
    """ì´ë¯¸ì§€ë¥¼ Supabase Storageì— ì—…ë¡œë“œí•˜ê³  ê³µê°œ URL ë°˜í™˜. ì‹¤íŒ¨ ì‹œ ë¹ˆ ë¬¸ìì—´."""
    supa_url = os.environ.get("SUPABASE_URL", "").rstrip("/")
    key = os.environ.get("SUPABASE_SERVICE_ROLE_KEY", "")
    if not supa_url or not key:
        return ""
    bucket = "news-images"
    req = urllib.request.Request(
        f"{supa_url}/storage/v1/object/{bucket}/{filename}",
        data=image_data,
        headers={
            "apikey": key,
            "Authorization": f"Bearer {key}",
            "Content-Type": content_type,
            "x-upsert": "true",
        },
        method="POST",
    )
    try:
        urllib.request.urlopen(req, timeout=30)
        public_url = f"{supa_url}/storage/v1/object/public/{bucket}/{filename}"
        print(f"    ì´ë¯¸ì§€ ì—…ë¡œë“œ ì™„ë£Œ: {filename}")
        return public_url
    except Exception as e:
        print(f"    ì´ë¯¸ì§€ ì—…ë¡œë“œ ì‹¤íŒ¨ ({filename}): {e}", file=sys.stderr)
        return ""


def process_news_images(news_items: list) -> None:
    """ê° ë‰´ìŠ¤ í•­ëª©ì˜ ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ì—¬ Supabase Storageì— ì—…ë¡œë“œ.
    news_items[i]['image_url']ì„ Supabase ê³µê°œ URLë¡œ êµì²´ (ì‹¤íŒ¨ ì‹œ ë¹ˆ ë¬¸ìì—´ë¡œ ì„¤ì •)."""
    has_images = any(item.get("image_url") for item in news_items)
    if not has_images:
        print("  ì´ë¯¸ì§€ ì—†ìŒ â€” ê±´ë„ˆëœ€")
        return

    _ensure_supabase_bucket("news-images")
    date_prefix = datetime.now(KST).strftime("%Y%m%d")
    ext_map = {"image/jpeg": "jpg", "image/png": "png", "image/webp": "webp", "image/gif": "gif"}

    for i, item in enumerate(news_items):
        raw_url = item.get("image_url", "")
        if not raw_url:
            continue
        print(f"  [{i+1}] ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘: {raw_url[:70]}")
        image_data, ct = _download_image(raw_url)
        if not image_data:
            item["image_url"] = ""
            continue
        ext = ext_map.get(ct, "jpg")
        title_hash = hashlib.md5(item["title"].encode()).hexdigest()[:8]
        filename = f"{date_prefix}/{i+1}_{title_hash}.{ext}"
        item["image_url"] = _upload_image_to_supabase(image_data, filename, ct)


def fetch_top_news(active_sources: list, count: int = 3) -> list:
    """í™œì„±í™”ëœ RSS í”¼ë“œì—ì„œ ìµœì‹  ë‰´ìŠ¤ ìˆ˜ì§‘. ì†ŒìŠ¤ë³„ë¡œ ìˆœí™˜í•˜ë©° countê°œ ìˆ˜ì§‘."""
    news_items = []
    cutoff = datetime.now(timezone.utc) - timedelta(days=3)

    # active_sources ê¸°ë°˜ í”¼ë“œ ëª©ë¡ (ALL_SOURCES ìˆœì„œ ìœ ì§€)
    feeds = [(name, url) for name, url in ALL_SOURCES.items() if name in active_sources]

    # Supabase ì„¤ì •ì— ì—†ë”ë¼ë„ êµ¬ê¸€ë‰´ìŠ¤ëŠ” í•­ìƒ ì•ì— ì¶”ê°€ (GitHub Actionsì—ì„œ ì•ˆì •ì ìœ¼ë¡œ ì ‘ê·¼ ê°€ëŠ¥)
    guaranteed_feeds = [
        (name, ALL_SOURCES[name]) for name in GUARANTEED_SOURCES
        if name not in active_sources and name in ALL_SOURCES
    ]
    feeds = guaranteed_feeds + feeds

    # ì¼ë¶€ í•œêµ­ ë‰´ìŠ¤ ì‚¬ì´íŠ¸ëŠ” ë´‡ User-Agent ì°¨ë‹¨ â†’ ë¸Œë¼ìš°ì €ì²˜ëŸ¼ ìœ„ì¥
    ua_headers = {
        "User-Agent": (
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
            "AppleWebKit/537.36 (KHTML, like Gecko) "
            "Chrome/124.0.0.0 Safari/537.36"
        )
    }

    for source_name, feed_url in feeds:
        if len(news_items) >= count:
            break
        try:
            print(f"  [{source_name}] ìˆ˜ì§‘ ì¤‘...")

            # íƒ€ì„ì•„ì›ƒ 15ì´ˆ ì„¤ì • (ë¬´í•œ ëŒ€ê¸° ë°©ì§€)
            prev_timeout = socket.getdefaulttimeout()
            socket.setdefaulttimeout(15)
            try:
                feed = feedparser.parse(feed_url, request_headers=ua_headers)
            finally:
                socket.setdefaulttimeout(prev_timeout)

            # ë„¤íŠ¸ì›Œí¬/íŒŒì‹± ì˜¤ë¥˜ë¡œ í•­ëª©ì´ ì—†ëŠ” ê²½ìš°
            if not feed.entries:
                reason = str(getattr(feed, "bozo_exception", "í•­ëª© ì—†ìŒ"))
                print(f"  [{source_name}] ê±´ë„ˆëœ€ â€” {reason}", file=sys.stderr)
                continue

            # í•œ ì†ŒìŠ¤ì—ì„œ í•„ìš”í•œ ë§Œí¼ ì—¬ëŸ¬ ê¸°ì‚¬ ìˆ˜ì§‘ (ê¸°ì¡´: 1ê°œ ê³ ì • â†’ ê°œì„ : ìµœëŒ€ neededê°œ)
            needed = count - len(news_items)
            collected = 0
            for entry in feed.entries:
                if collected >= needed:
                    break
                parsed_time = entry.get("published_parsed") or entry.get("updated_parsed")
                pub_time_str = ""
                if parsed_time:
                    pub_dt = datetime(*parsed_time[:6], tzinfo=timezone.utc)
                    if pub_dt < cutoff:
                        continue  # ë„ˆë¬´ ì˜¤ë˜ëœ ê¸°ì‚¬ ê±´ë„ˆëœ€
                    pub_time_str = pub_dt.astimezone(KST).strftime("%m/%d %H:%M")
                title = entry.get("title", "").strip()
                summary = entry.get("summary", entry.get("description", title)).strip()
                link = entry.get("link", "")
                # Google News ë‹¨ì¶• URL â†’ ì‹¤ì œ ê¸°ì‚¬ URL ë³€í™˜
                if "news.google.com" in link:
                    link = _resolve_google_news_url(link)
                summary = re.sub(r"<[^>]+>", "", summary).strip()
                if len(summary) > 500:
                    summary = summary[:497] + "..."
                if not title:
                    continue
                news_items.append({
                    "source": source_name,
                    "title": title,
                    "summary": summary,
                    "link": link,
                    "published_at": pub_time_str,
                    "image_url": _extract_image_url(entry),
                })
                collected += 1

            if collected > 0:
                print(f"  [{source_name}] OK: {collected}ê°œ ìˆ˜ì§‘")
            else:
                print(f"  [{source_name}] ìµœê·¼ ë‰´ìŠ¤ ì—†ìŒ", file=sys.stderr)

        except Exception as e:
            print(f"  [{source_name}] ì‹¤íŒ¨: {e}", file=sys.stderr)

    if len(news_items) < count:
        print(f"ê²½ê³ : {count}ê°œ ì¤‘ {len(news_items)}ê°œë§Œ ìˆ˜ì§‘ë¨", file=sys.stderr)

    return news_items[:count]


# ---------------------------------------------------------------------------
# 2. AI ì•„ì´ë””ì–´ ìƒì„±
# ---------------------------------------------------------------------------

def generate_idea(news_items: list, prompt_template: str = "") -> str:
    """Claude AIë¡œ ë‰´ìŠ¤ 3ê°œë¥¼ ê²°í•©í•˜ì—¬ ì•„ì´ë””ì–´ ìƒì„±."""
    client = anthropic.Anthropic()

    news_block = "\n\n".join(
        f"**ë‰´ìŠ¤ {i + 1} ({item['source']}"
        + (f", {item['published_at']}" if item.get('published_at') else "")
        + f")**\nì œëª©: {item['title']}\në‚´ìš©: {item['summary']}"
        for i, item in enumerate(news_items)
    )

    template = prompt_template.strip() if prompt_template and prompt_template.strip() else DEFAULT_PROMPT_TEMPLATE

    if "{news_block}" in template:
        prompt = template.replace("{news_block}", news_block)
    else:
        prompt = template + "\n\n" + news_block

    message = client.messages.create(
        model="claude-opus-4-5",
        max_tokens=2048,
        messages=[{"role": "user", "content": prompt}],
    )

    return message.content[0].text


# ---------------------------------------------------------------------------
# 3. Supabase ì €ì¥
# ---------------------------------------------------------------------------

def save_to_supabase(news_items: list, idea: str, generated_at: datetime) -> bool:
    """Supabase news_ideas í…Œì´ë¸”ì— ê²°ê³¼ ì €ì¥ (REST API ì‚¬ìš©)."""
    url = os.environ.get("SUPABASE_URL", "").rstrip("/")
    key = os.environ.get("SUPABASE_SERVICE_ROLE_KEY", "")

    if not url or not key:
        print("ê²½ê³ : SUPABASE_URL ë˜ëŠ” SUPABASE_SERVICE_ROLE_KEYê°€ ì—†ìŠµë‹ˆë‹¤.", file=sys.stderr)
        return False

    payload = json.dumps({
        "generated_at": generated_at.isoformat(),
        "news_items": news_items,
        "idea": idea,
    }).encode("utf-8")

    req = urllib.request.Request(
        f"{url}/rest/v1/news_ideas",
        data=payload,
        headers={**_supabase_headers(), "Prefer": "return=minimal"},
        method="POST",
    )

    try:
        with urllib.request.urlopen(req) as resp:
            print(f"Supabase ì €ì¥ ì™„ë£Œ (status: {resp.status})")
            return True
    except urllib.error.HTTPError as e:
        body = e.read().decode()
        print(f"Supabase ì €ì¥ ì‹¤íŒ¨ ({e.code}): {body}", file=sys.stderr)
        return False


# ---------------------------------------------------------------------------
# 4. í…”ë ˆê·¸ë¨ ë°œì†¡
# ---------------------------------------------------------------------------

def _send_telegram_photos(token: str, chat_id: str, news_items: list) -> None:
    """ë‰´ìŠ¤ í•­ëª©ë³„ ì´ë¯¸ì§€ë¥¼ í…”ë ˆê·¸ë¨ sendPhotoë¡œ ê°œë³„ ë°œì†¡.
    ìº¡ì…˜ì— ì œëª© + ì›ë¬¸ ë§í¬ í¬í•¨. Supabase Storage URLì„ ì´ë¯¸ì§€ë¡œ ì‚¬ìš©."""
    for i, item in enumerate(news_items):
        img = item.get("image_url", "")
        if not img:
            continue
        pub = f" {item['published_at']}" if item.get('published_at') else ""
        caption = f"[{item['source']}]{pub} {item['title']}"
        payload = json.dumps({
            "chat_id": chat_id,
            "photo": img,
            "caption": caption,
        }).encode("utf-8")
        req = urllib.request.Request(
            f"https://api.telegram.org/bot{token}/sendPhoto",
            data=payload,
            headers={"Content-Type": "application/json"},
            method="POST",
        )
        try:
            with urllib.request.urlopen(req, timeout=20) as resp:
                result = json.loads(resp.read().decode())
                if result.get("ok"):
                    print(f"  [{i+1}] ì´ë¯¸ì§€ ë°œì†¡ ì™„ë£Œ")
                else:
                    print(f"  [{i+1}] ì´ë¯¸ì§€ ë°œì†¡ ì‹¤íŒ¨: {result.get('description')}", file=sys.stderr)
        except Exception as e:
            print(f"  [{i+1}] ì´ë¯¸ì§€ ë°œì†¡ ì˜¤ë¥˜: {e}", file=sys.stderr)


def send_to_telegram(news_items: list, idea: str, generated_at: datetime) -> bool:
    """í…”ë ˆê·¸ë¨ ë´‡ìœ¼ë¡œ ê²°ê³¼ ë©”ì‹œì§€ ë°œì†¡."""
    token = os.environ.get("TELEGRAM_BOT_TOKEN", "")
    chat_id = os.environ.get("TELEGRAM_CHAT_ID", "")

    if not token or not chat_id:
        print("ê²½ê³ : TELEGRAM_BOT_TOKEN ë˜ëŠ” TELEGRAM_CHAT_IDê°€ ì—†ìŠµë‹ˆë‹¤.", file=sys.stderr)
        return False

    # ì‹¤ì œ ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ ë¨¼ì € ì´ë¯¸ì§€ ê·¸ë£¹ìœ¼ë¡œ ì „ì†¡
    _send_telegram_photos(token, chat_id, news_items)

    timestamp = generated_at.strftime("%Yë…„ %mì›” %dì¼ %Hì‹œ (KST)")

    # idea í›„ì²˜ë¦¬: ê¹¨ì§„ URL ë° ì´ë¯¸ì§€ ì—†ìŒ í…ìŠ¤íŠ¸ ì œê±°
    idea = re.sub(r'\(https?://[^\)]+\)', '', idea)  # [ì›ë¬¸ ë§í¬](url) â†’ [ì›ë¬¸ ë§í¬]
    idea = re.sub(r'ğŸ–¼ï¸[^\n]*ì´ë¯¸ì§€[^\n]*ì—†ìŒ[^\n]*\n?', '', idea)
    idea = re.sub(r'ğŸ–¼ï¸[^\n]*\n?', '', idea)
    idea = re.sub(r'\n{3,}', '\n\n', idea).strip()

    # ë‰´ìŠ¤ ëª©ë¡: ê²Œì‹œ ì‹œê° + ì œëª© + ì‹¤ì œ ì›ë¬¸ ë§í¬
    news_lines = "\n".join(
        f"{i + 1}. [{item['source']}]"
        + (f" {item['published_at']}" if item.get('published_at') else "")
        + f" {item['title']}"
        + (f"\n   <a href=\"{item['link']}\">ì›ë¬¸ ë³´ê¸°</a>" if item.get('link') else "")
        for i, item in enumerate(news_items)
    )

    message = (
        f"<b>ë‰´ìŠ¤ ì•„ì´ë””ì–´ ë¦¬í¬íŠ¸</b>\n"
        f"<i>{timestamp}</i>\n\n"
        f"<b>ìˆ˜ì§‘ëœ ë‰´ìŠ¤</b>\n"
        f"{news_lines}\n\n"
        f"<b>AI ë„ì¶œ ì•„ì´ë””ì–´</b>\n"
        f"{idea[:2000]}"
    )

    payload = json.dumps({
        "chat_id": chat_id,
        "text": message,
        "parse_mode": "HTML",
        "disable_web_page_preview": True,
    }).encode("utf-8")

    req = urllib.request.Request(
        f"https://api.telegram.org/bot{token}/sendMessage",
        data=payload,
        headers={"Content-Type": "application/json"},
        method="POST",
    )

    try:
        with urllib.request.urlopen(req) as resp:
            result = json.loads(resp.read().decode())
            if result.get("ok"):
                print("í…”ë ˆê·¸ë¨ ë°œì†¡ ì™„ë£Œ")
                return True
            else:
                print(f"í…”ë ˆê·¸ë¨ ë°œì†¡ ì‹¤íŒ¨: {result}", file=sys.stderr)
                return False
    except Exception as e:
        print(f"í…”ë ˆê·¸ë¨ ë°œì†¡ ì˜¤ë¥˜: {e}", file=sys.stderr)
        return False


# ---------------------------------------------------------------------------
# ë©”ì¸
# ---------------------------------------------------------------------------

def main():
    print("=== ë‰´ìŠ¤ ì•„ì´ë””ì–´ ì—ì´ì „íŠ¸ ì‹œì‘ ===\n")

    print("[ì„¤ì •] Supabaseì—ì„œ ì„¤ì • ë¡œë“œ ì¤‘...")
    settings = fetch_settings()

    if not settings["enabled"]:
        print("ì—ì´ì „íŠ¸ê°€ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì¢…ë£Œí•©ë‹ˆë‹¤.")
        sys.exit(0)

    run_every = int(settings["run_every_hours"])
    is_manual = os.environ.get("GITHUB_EVENT_NAME") == "workflow_dispatch"
    if run_every > 1 and not is_manual:
        current_hour_utc = datetime.now(timezone.utc).hour
        if current_hour_utc % run_every != 0:
            print(f"í˜„ì¬ {current_hour_utc}ì‹œ (UTC) â€” {run_every}ì‹œê°„ ê°„ê²© ë¯¸í•´ë‹¹. ê±´ë„ˆëœ€.")
            sys.exit(0)
    if is_manual:
        print("ìˆ˜ë™ ì‹¤í–‰ â€” ì‹œê°„ ê°„ê²© ì²´í¬ ê±´ë„ˆëœ€.")

    active_sources = settings["active_sources"]
    prompt_template = settings.get("prompt_template", "")
    print(f"í™œì„± ì†ŒìŠ¤: {active_sources} | ì‹¤í–‰ ì£¼ê¸°: {run_every}ì‹œê°„\n")

    print("[1/4] ì£¼ìš” ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘...")
    news_items = fetch_top_news(active_sources, 3)
    if not news_items:
        print("ì˜¤ë¥˜: ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.", file=sys.stderr)
        sys.exit(1)
    print(f"ìˆ˜ì§‘ ì™„ë£Œ: {len(news_items)}ê°œ\n")

    print("[2/4] ë‰´ìŠ¤ ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ (ë‹¤ìš´ë¡œë“œ â†’ Supabase Storage)...")
    process_news_images(news_items)
    print()

    print("[3/4] Claude AIë¡œ ì•„ì´ë””ì–´ ìƒì„± ì¤‘...")
    idea = generate_idea(news_items, prompt_template)
    print("ìƒì„± ì™„ë£Œ\n")

    generated_at = datetime.now(KST)

    print("[4/4] ê²°ê³¼ ì €ì¥ & ë°œì†¡ ì¤‘...")
    supabase_ok = save_to_supabase(news_items, idea, generated_at)
    telegram_ok = send_to_telegram(news_items, idea, generated_at)

    print("\n=== ì™„ë£Œ ===")
    print(f"  Supabase: {'OK' if supabase_ok else 'FAIL'}")
    print(f"  Telegram: {'OK' if telegram_ok else 'FAIL'}")

    if not supabase_ok and not telegram_ok:
        sys.exit(1)


if __name__ == "__main__":
    main()
